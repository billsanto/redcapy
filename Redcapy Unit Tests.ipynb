{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redcapy Unit Testing\n",
    "##### WARNING: This notebook contains unit tests. While they may be used liberally in a development stage project, import tests should NOT be used in a production project.\n",
    "- Variable names should reflect names within your Redcap project in order for the tests to succeed. This is merely a framework to be modified for a given project for which you have API access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "import unittest\n",
    "import json\n",
    "import pprint\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "from redcap.redcapy import Redcapy\n",
    "from datetime import datetime, date, timedelta\n",
    "from unittest import TestLoader, TextTestRunner\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The following environment variables should be created for the token and url first.\n",
    "- REDCAP_API: The token assigned by your Redcap administrator\n",
    "- REDCAP_URL: The URL associated with your institution's address to interact with the API\n",
    "- Reference: https://www.google.com/search?q=create+environment+variables\n",
    "\n",
    "Alternatively, you can manually overwrite the os.environ commands in each test with your own values, or access your sensitive data in some other more secure manner.\n",
    "However, do not publish your token online!\n",
    "\n",
    "By default, all Redcap protocols use record_id as the primary identifier for each participant.\n",
    "If not using the default, define the alternative in your protocol below. Normally, this may be 'record_id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record_id = 'prescreening_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Export Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataExport(unittest.TestCase):\n",
    "    \"\"\"\n",
    "        Test project data export\n",
    "        Replace various fields, such as token, url, forms, and fields as needed to suit a given project\n",
    "    \"\"\"\n",
    "    \n",
    "    REDCAP_API = os.environ['REDCAP_API_BEECON_DEV']\n",
    "    REDCAP_URL = os.environ['REDCAP_URL']  \n",
    "    \n",
    "    \n",
    "    def test_basic_export(self):\n",
    "        \"\"\"\n",
    "            Key Variables\n",
    "            -------------\n",
    "                threshold: Integer defining the minimum number of records expected\n",
    "                fields_to_print_list: Modify to suit\n",
    "            \n",
    "        \"\"\"\n",
    "        threshold = 1\n",
    "        fields_to_print_list = [record_id, 'randomization_id']\n",
    "        result_limit = 3\n",
    "        \n",
    "        rcap = Redcapy(api_token=self.REDCAP_API, redcap_url=self.REDCAP_URL)\n",
    "        return_value_json = rcap.export_records()\n",
    "\n",
    "        if 'error' in return_value_json:  # no content\n",
    "            print(return_value_json)\n",
    "        else:\n",
    "            for i, record in zip(range(result_limit), return_value_json):\n",
    "                print({key: return_value_json[i].get(key) for key in fields_to_print_list})\n",
    "        \n",
    "        self.assertTrue(len(return_value_json) >= threshold, msg='Was expecting to see more than 1')\n",
    "        \n",
    "     \n",
    "    def test_optional_fields_export(self):\n",
    "        \"\"\"\n",
    "            Key Variables\n",
    "            -------------\n",
    "                threshold: Integer defining the minimum number of records expected\n",
    "            \n",
    "        \"\"\"\n",
    "        threshold = 1\n",
    "        args = {}  # initializing dict of kwargs\n",
    "        result_limit = 1\n",
    "\n",
    "        forms_str = 'dental_screening'  # specify a form to limit output\n",
    "        \n",
    "        args['forms'] = forms_str\n",
    "        args['rawOrLabel'] = 'label'\n",
    "        args['rawOrLabelHeaders'] = 'label'\n",
    "        \n",
    "        rcap = Redcapy(api_token=self.REDCAP_API, redcap_url=self.REDCAP_URL)\n",
    "        return_value_json = rcap.export_records(**args)\n",
    "\n",
    "        if 'error' in return_value_json:  # no content\n",
    "            print(return_value_json)\n",
    "        else:\n",
    "            for i, record in zip(range(result_limit), return_value_json):\n",
    "                print({key: return_value_json[i].get(key) for key, value in record.items() })\n",
    "        \n",
    "        self.assertTrue(len(return_value_json) >= threshold, msg='Was expecting to see more than 1')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Export Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomization_id': '1.001', 'prescreening_id': '101'}\n",
      "{'randomization_id': '', 'prescreening_id': '101'}\n",
      "{'randomization_id': '', 'prescreening_id': '101'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ss02_untxcaries': \"No  <b><font color='blue'>[No]</font></b>\", 'ss04_dmftge7': \"No  <b><font color='blue'>[No]</font></b>\", 'mh01_dtxcomp': \"No  <b><font color='blue'>[No]</font></b>\", 'mh04_asthma': \"No  <b><font color='blue'>[No]</font></b>\", 'mh02_fvallergy': \"No  <b><font color='blue'>[No]</font></b>\", 'mh03_latexallergy': \"No  <b><font color='blue'>[No]</font></b>\", 'mh06_heartprob': \"No  <b><font color='blue'>[No]</font></b>\", 'mh09c_participate': '', 'ss01_numteeth': '0', 'mh04a_if_yes_explain': '', 'mh01b_type_dtxcomp': '', 'ss03_cariesexp': \"No  <b><font color='blue'>[No]</font></b>\", 'mh03a_gloves_available': '', 'mh07_chrondx': \"No  <b><font color='blue'>[No]</font></b>\", 'mh09_meds': \"No  <b><font color='blue'>[No]</font></b>\", 'mh04b_asthma': '', 'mh08_organxplt': \"No  <b><font color='blue'>[No]</font></b>\", 'ss07_notes': '', 'ss06_franklscore': '3 Positive', 'dental_screening_complete': 'Incomplete', 'mh05_tb': \"No  <b><font color='blue'>[No]</font></b>\", 'mh09b_typemeds': '', 'ss05_adaclass': '2 with carious lesion but no pain, infection or abscess', 'mh01a_type_dtxcomp': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 3.310s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TestDataExport()\n",
    "suite = TestLoader().loadTestsFromModule(te)\n",
    "TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MetaData Export Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMetaDataExport(unittest.TestCase):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    REDCAP_API = os.environ['REDCAP_API_BEECON_DEV']\n",
    "    REDCAP_URL = os.environ['REDCAP_URL']   \n",
    "    \n",
    "    \n",
    "    def test_basic_export(self):\n",
    "        rcap = Redcapy(api_token=self.REDCAP_API, redcap_url=self.REDCAP_URL)\n",
    "\n",
    "#         return_value_json = self.rcap.export_records(format='json', return_format='json', exportCheckboxLabel='true')\n",
    "        return_value_json = rcap.export_data_dictionary()\n",
    "        \n",
    "        if 'error' in return_value_json:  # no content\n",
    "            print(return_value_json)\n",
    "        else:\n",
    "            print('Partial output follows:\\n')\n",
    "            pprint.pprint(return_value_json[:2])\n",
    "            \n",
    "        threshold = 1\n",
    "        self.assertTrue(len(return_value_json) > 1)  # Protocol presumed to have more than threshold events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute MetaData Export Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial output follows:\n",
      "\n",
      "[{'branching_logic': '',\n",
      "  'custom_alignment': '',\n",
      "  'field_annotation': '',\n",
      "  'field_label': 'Pre-Screening ID',\n",
      "  'field_name': 'prescreening_id',\n",
      "  'field_note': '',\n",
      "  'field_type': 'text',\n",
      "  'form_name': 'screening_eligibility',\n",
      "  'identifier': '',\n",
      "  'matrix_group_name': '',\n",
      "  'matrix_ranking': '',\n",
      "  'question_number': '',\n",
      "  'required_field': '',\n",
      "  'section_header': '',\n",
      "  'select_choices_or_calculations': '',\n",
      "  'text_validation_max': '',\n",
      "  'text_validation_min': '',\n",
      "  'text_validation_type_or_show_slider_number': ''},\n",
      " {'branching_logic': '',\n",
      "  'custom_alignment': '',\n",
      "  'field_annotation': '',\n",
      "  'field_label': 'Date',\n",
      "  'field_name': 'eligibility_date',\n",
      "  'field_note': '',\n",
      "  'field_type': 'text',\n",
      "  'form_name': 'screening_eligibility',\n",
      "  'identifier': '',\n",
      "  'matrix_group_name': '',\n",
      "  'matrix_ranking': '',\n",
      "  'question_number': '',\n",
      "  'required_field': 'y',\n",
      "  'section_header': '',\n",
      "  'select_choices_or_calculations': '',\n",
      "  'text_validation_max': '',\n",
      "  'text_validation_min': '',\n",
      "  'text_validation_type_or_show_slider_number': 'date_mdy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.010s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TestMetaDataExport()\n",
    "suite = TestLoader().loadTestsFromModule(t)\n",
    "TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events Export Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestEventExport(unittest.TestCase):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    REDCAP_API = os.environ['REDCAP_API_BEECON_DEV']\n",
    "    REDCAP_URL = os.environ['REDCAP_URL']     \n",
    "    \n",
    "    \n",
    "    def test_basic_export(self):\n",
    "        rcap = Redcapy(api_token=self.REDCAP_API, redcap_url=self.REDCAP_URL)\n",
    "\n",
    "        return_value_json = rcap.export_events()\n",
    "\n",
    "        if 'error' in return_value_json:  # no content\n",
    "            print(return_value_json)\n",
    "        else:\n",
    "            pprint.pprint(return_value_json)\n",
    "            \n",
    "        threshold = 1\n",
    "        self.assertTrue(len(return_value_json) > threshold)  # Protocol presumed to have more than threshold events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Event Export Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'arm_num': '1',\n",
      "  'custom_event_label': None,\n",
      "  'day_offset': '0',\n",
      "  'event_name': 'Screening',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'screening_arm_1'},\n",
      " {'arm_num': '2',\n",
      "  'custom_event_label': '00_week_baseline',\n",
      "  'day_offset': '0',\n",
      "  'event_name': 'Baseline',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'baseline_arm_2'},\n",
      " {'arm_num': '2',\n",
      "  'custom_event_label': '10_week_followup1',\n",
      "  'day_offset': '70',\n",
      "  'event_name': 'Follow-up 1',\n",
      "  'offset_max': '30',\n",
      "  'offset_min': '30',\n",
      "  'unique_event_name': 'followup_1_arm_2'},\n",
      " {'arm_num': '2',\n",
      "  'custom_event_label': '99_week_floating',\n",
      "  'day_offset': '71',\n",
      "  'event_name': 'Floating',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'floating_arm_2'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '00_week_b',\n",
      "  'day_offset': '0',\n",
      "  'event_name': 'Baseline',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'baseline_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '01_week',\n",
      "  'day_offset': '7',\n",
      "  'event_name': 'Week 1',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_1_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '02_week',\n",
      "  'day_offset': '14',\n",
      "  'event_name': 'Week 2',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_2_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '03_week',\n",
      "  'day_offset': '21',\n",
      "  'event_name': 'Week 3',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_3_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '04_week',\n",
      "  'day_offset': '28',\n",
      "  'event_name': 'Week 4',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_4_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '05_week',\n",
      "  'day_offset': '35',\n",
      "  'event_name': 'Week 5',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_5_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '06_week',\n",
      "  'day_offset': '42',\n",
      "  'event_name': 'Week 6',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_6_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '07_week',\n",
      "  'day_offset': '49',\n",
      "  'event_name': 'Week 7',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_7_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '08_week',\n",
      "  'day_offset': '56',\n",
      "  'event_name': 'Week 8',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_8_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '09_week',\n",
      "  'day_offset': '63',\n",
      "  'event_name': 'Week 9',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'week_9_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '10_week_f1',\n",
      "  'day_offset': '70',\n",
      "  'event_name': 'Follow-up 1',\n",
      "  'offset_max': '30',\n",
      "  'offset_min': '30',\n",
      "  'unique_event_name': 'followup_1_arm_3'},\n",
      " {'arm_num': '3',\n",
      "  'custom_event_label': '99_week_fu',\n",
      "  'day_offset': '71',\n",
      "  'event_name': 'Floating',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'floating_arm_3'},\n",
      " {'arm_num': '4',\n",
      "  'custom_event_label': '00_week_baseline',\n",
      "  'day_offset': '0',\n",
      "  'event_name': 'Baseline',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'baseline_arm_4'},\n",
      " {'arm_num': '4',\n",
      "  'custom_event_label': '10_week_followup1',\n",
      "  'day_offset': '70',\n",
      "  'event_name': 'Follow-up 1',\n",
      "  'offset_max': '30',\n",
      "  'offset_min': '30',\n",
      "  'unique_event_name': 'followup_1_arm_4'},\n",
      " {'arm_num': '4',\n",
      "  'custom_event_label': '19_week_followup2',\n",
      "  'day_offset': '133',\n",
      "  'event_name': 'Follow-up 2',\n",
      "  'offset_max': '30',\n",
      "  'offset_min': '30',\n",
      "  'unique_event_name': 'followup_2_arm_4'},\n",
      " {'arm_num': '4',\n",
      "  'custom_event_label': '99_week_floating',\n",
      "  'day_offset': '134',\n",
      "  'event_name': 'Floating',\n",
      "  'offset_max': '0',\n",
      "  'offset_min': '0',\n",
      "  'unique_event_name': 'floating_arm_4'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.566s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TestEventExport()\n",
    "suite = TestLoader().loadTestsFromModule(t)\n",
    "TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import Unit Test Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestImport(unittest.TestCase):\n",
    "    \"\"\"\n",
    "        return_key can be 'ids' or 'count'\n",
    "\n",
    "        Fields defined in each import obviously should exist in the project before attempting.\n",
    "        \n",
    "    \"\"\"\n",
    "    REDCAP_API = os.environ['REDCAP_API_BEECON_DEV']\n",
    "    REDCAP_URL = os.environ['REDCAP_URL']      \n",
    "\n",
    "\n",
    "    def __import_records__(self, data_to_upload, returnContent):\n",
    "        \"\"\"\n",
    "            Common private code for the import unit tests\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "                data_to_upload_list: a list of records to import, where each record is a dict\n",
    "        \n",
    "        \"\"\"\n",
    "        rcap = Redcapy(api_token=self.REDCAP_API, redcap_url=self.REDCAP_URL)\n",
    "        \n",
    "        if type(data_to_upload) == dict:  # a dict is presumed to be a single record\n",
    "            data_to_upload_list = [data_to_upload]\n",
    "        else:\n",
    "            data_to_upload_list = data_to_upload\n",
    "            \n",
    "        data_to_upload_list_count = len(data_to_upload_list)\n",
    "        data_to_upload_str = json.dumps(data_to_upload_list)\n",
    "        \n",
    "        return_value_json = rcap.import_records(data_to_upload=data_to_upload_str, \n",
    "                                                returnFormat='json',\n",
    "                                                returnContent=returnContent)\n",
    "\n",
    "        return return_value_json\n",
    "          \n",
    "        \n",
    "    def test_malformed_record_id_import(self):\n",
    "        \"\"\"\n",
    "            Attempt to import a malformed id\n",
    "            \n",
    "            data_to_upload_list fields should be modified to reflect your protocol's data\n",
    "            data_to_upload_list is a list of dicts, to be converted into a json object\n",
    "            \n",
    "            Key Variables\n",
    "            -------------\n",
    "                data_to_upload_list: list of dict study key/value pairs                \n",
    "            \n",
    "            On error, expect to see the following json (generated by the server): \n",
    "                {\"error\": \"The participant id field (record_id) is missing.\"}\n",
    "        \"\"\"\n",
    "        print('Begin test_malformed_record_id_import test') \n",
    "        \n",
    "        data_to_upload_list = [{'record_i': '2', 'subject_id': '435', 'redcap_event_name': 'screening_arm_1'},\n",
    "                          {'record_i': '1', 'subject_id': '45', 'redcap_event_name': 'screening_arm_1'},\n",
    "                          {record_id: '3', 'subject_id': '3', 'redcap_event_name': 'screening_arm_1'}]    \n",
    "        \n",
    "        rcap = Redcapy(api_token=self.REDCAP_API, redcap_url=self.REDCAP_URL)        \n",
    "        data_to_upload_str = json.dumps(data_to_upload_list)\n",
    "        return_value_json = rcap.import_records(data_to_upload=data_to_upload_str)\n",
    "\n",
    "        self.assertTrue('error' in return_value_json, \n",
    "                        msg='test_malformed_record_id_import method did not throw an error upon import')\n",
    "        print('End test_malformed_record_id_import test\\n')\n",
    "      \n",
    "    def test_iterative_import(self):   \n",
    "        \"\"\"\n",
    "            Import a list of records individually, rather than as a batch upload\n",
    "            \n",
    "            Key Variables\n",
    "            -------------\n",
    "                return_key: id or count\n",
    "                data_to_upload_list: list of dict study key/value pairs\n",
    "                \n",
    "        \"\"\"\n",
    "        print('Begin test_iterative_import test')\n",
    "        \n",
    "        return_key = 'count'\n",
    "        create_record_count = 16\n",
    "        base_consent_date = date(2017, 6, 1)\n",
    "        \n",
    "        # Generate a list of records to upload\n",
    "        data_to_upload_list = [{record_id: str(i+101), \n",
    "                                'redcap_event_name': 'screening_arm_1', \n",
    "                                'ss01_numteeth': i, \n",
    "                                'consent_date': (base_consent_date + timedelta(days=i)).strftime('%Y-%m-%d') }\n",
    "                               for i in range(create_record_count)\n",
    "                              ]\n",
    "        print('List of records to import into Redcap:')\n",
    "        pprint.pprint(data_to_upload_list)\n",
    "                \n",
    "        data_to_upload_list_count = len(data_to_upload_list)\n",
    "        return_count = 0\n",
    "        import_attempt_count = 0\n",
    "        \n",
    "        for i, record in enumerate(data_to_upload_list):\n",
    "            import_list = [data_to_upload_list[i]]\n",
    "            import_attempt_count += 1\n",
    "            return_value_json = self.__import_records__(data_to_upload=import_list, returnContent=return_key) \n",
    "\n",
    "            if 'count' in return_value_json and return_value_json['count'] == 1:\n",
    "                return_count += 1\n",
    "            elif 'error' in return_value_json:\n",
    "                if record_id in import_list[0]:\n",
    "                    print(record_id, import_list, ' failed to import.')\n",
    "                else:\n",
    "                    print('Test record does not have a', 'record id')\n",
    "                    \n",
    "                print('Error returned from server:', return_value_json['error'])\n",
    "            else:\n",
    "                print(record_id, import_list, ' failed to import.')\n",
    "                print('Server returned : ', return_value_json)                \n",
    "                \n",
    "        print('{} distinct imports attempted, {} successes from a list of {} records'.format(import_attempt_count, \n",
    "                                                                                    return_count, \n",
    "                                                                                    data_to_upload_list_count))\n",
    "        self.assertEqual(data_to_upload_list_count, return_count, msg='At least one record was not imported properly.')\n",
    "        print('End test_iterative_import test\\n')\n",
    "        \n",
    "    def test_basic_import_delete(self):\n",
    "        \"\"\"\n",
    "            First create a record using a randomly generated ID, then delete it\n",
    "            \n",
    "            Key Variables\n",
    "            -------------\n",
    "                id = the record_id to create, then delete\n",
    "                return_key: id or count\n",
    "                data_to_upload_list: list of dict study key/value pairs            \n",
    "        \"\"\"\n",
    "        print('Begin test_basic_import_delete test')\n",
    "        id = str(hashlib.sha1().hexdigest()[:16])\n",
    "        return_key = 'count'\n",
    "        \n",
    "        rcap = Redcapy(api_token=self.REDCAP_API, redcap_url=self.REDCAP_URL)\n",
    "        \n",
    "        # Note: code requires modifications if the list is extended to length greater than 1\n",
    "        data_to_upload_list = [{record_id: id, 'redcap_event_name': 'screening_arm_1'}]\n",
    "        \n",
    "        data_to_upload_list_count = len(data_to_upload_list)\n",
    "        return_count = 0\n",
    "        import_attempt_count = 0\n",
    "\n",
    "        for i, record in enumerate(data_to_upload_list):\n",
    "            data_to_upload = [record]\n",
    "            import_attempt_count += 1\n",
    "            \n",
    "            print('Importing record ID', id)\n",
    "            \n",
    "            return_value_json = self.__import_records__(data_to_upload=data_to_upload, returnContent=return_key) \n",
    "\n",
    "            if 'count' in return_value_json and return_value_json['count'] == 1:\n",
    "                return_count += 1\n",
    "                print('ID', id, 'successfully imported.')\n",
    "            elif 'error' in return_value_json:\n",
    "                if record_id in data_to_upload:\n",
    "                    print(record_id, data_to_upload[record_id], ' failed to import.')\n",
    "                else:\n",
    "                    print('Test record does not have a record id')\n",
    "                    \n",
    "                print('Error returned from server:', return_value_json['error'])\n",
    "            else:\n",
    "                print(record_id, data_to_upload[record_id], ' failed to import.')\n",
    "                print('Server returned : ', return_value_json)    \n",
    "                \n",
    "            print('{} distinct imports attempted, {} successes from a list of {} records'.format(import_attempt_count, \n",
    "                                                                                    return_count, \n",
    "                                                                                    data_to_upload_list_count))                \n",
    "            if return_count == 1:\n",
    "                wait_seconds = 10\n",
    "                \n",
    "                print('Attempting to delete record for ID', id)\n",
    "                print('Please wait {} seconds to complete database delete operation'.format(wait_seconds))\n",
    "                print('Wait time may require adjustment if server is busy')\n",
    "                \n",
    "                delete_return_count = rcap.delete_record(id_to_delete=id)\n",
    "                \n",
    "                time.sleep(wait_seconds)\n",
    "            \n",
    "            if delete_return_count == 1:\n",
    "                print('ID', id, 'successfully deleted.')\n",
    "            elif return_count == 1:\n",
    "                print('ID', id, 'was imported but not successfully deleted.')\n",
    "                \n",
    "        self.assertTrue(data_to_upload_list_count == return_count and delete_return_count == return_count, \n",
    "                        msg='At least one record was not imported properly.')\n",
    "\n",
    "        print('End test_basic_import_delete test\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Import Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin test_basic_import_delete test\n",
      "Importing record ID da39a3ee5e6b4b0d\n",
      "ID da39a3ee5e6b4b0d successfully imported.\n",
      "1 distinct imports attempted, 1 successes from a list of 1 records\n",
      "Attempting to delete record for ID da39a3ee5e6b4b0d\n",
      "Please wait 10 seconds to complete database delete operation\n",
      "Wait time may require adjustment if server is busy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID da39a3ee5e6b4b0d successfully deleted.\n",
      "End test_basic_import_delete test\n",
      "\n",
      "Begin test_iterative_import test\n",
      "List of records to import into Redcap:\n",
      "[{'consent_date': '2017-06-01',\n",
      "  'prescreening_id': '101',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 0},\n",
      " {'consent_date': '2017-06-02',\n",
      "  'prescreening_id': '102',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 1},\n",
      " {'consent_date': '2017-06-03',\n",
      "  'prescreening_id': '103',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 2},\n",
      " {'consent_date': '2017-06-04',\n",
      "  'prescreening_id': '104',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 3},\n",
      " {'consent_date': '2017-06-05',\n",
      "  'prescreening_id': '105',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 4},\n",
      " {'consent_date': '2017-06-06',\n",
      "  'prescreening_id': '106',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 5},\n",
      " {'consent_date': '2017-06-07',\n",
      "  'prescreening_id': '107',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 6},\n",
      " {'consent_date': '2017-06-08',\n",
      "  'prescreening_id': '108',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 7},\n",
      " {'consent_date': '2017-06-09',\n",
      "  'prescreening_id': '109',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 8},\n",
      " {'consent_date': '2017-06-10',\n",
      "  'prescreening_id': '110',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 9},\n",
      " {'consent_date': '2017-06-11',\n",
      "  'prescreening_id': '111',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 10},\n",
      " {'consent_date': '2017-06-12',\n",
      "  'prescreening_id': '112',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 11},\n",
      " {'consent_date': '2017-06-13',\n",
      "  'prescreening_id': '113',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 12},\n",
      " {'consent_date': '2017-06-14',\n",
      "  'prescreening_id': '114',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 13},\n",
      " {'consent_date': '2017-06-15',\n",
      "  'prescreening_id': '115',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 14},\n",
      " {'consent_date': '2017-06-16',\n",
      "  'prescreening_id': '116',\n",
      "  'redcap_event_name': 'screening_arm_1',\n",
      "  'ss01_numteeth': 15}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 distinct imports attempted, 16 successes from a list of 16 records\n",
      "End test_iterative_import test\n",
      "\n",
      "Begin test_malformed_record_id_import test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End test_malformed_record_id_import test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 20.928s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the order of operations may differ from how they appear in the test\n",
    "t = TestImport()\n",
    "suite = TestLoader().loadTestsFromModule(t)\n",
    "TextTestRunner().run(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
